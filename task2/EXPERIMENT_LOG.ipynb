{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Part I**** - Use this\n",
    "[dataset](https://www.dropbox.com/s/pan6mutc5xj5kj0/trainPart1.zip) to\n",
    "train a CNN. Use no other data source or pretrained networks, and\n",
    "explain your design choices during preprocessing, model building and\n",
    "training. Also, cite the sources you used to borrow techniques. A test\n",
    "set will be provided later to judge the performance of your classifier.\n",
    "Please save your model checkpoints.\n",
    "\n",
    "****Dataset Overview****\n",
    "\n",
    "The dataset consists of 62 classes, with 40 samples of each sample.\n",
    "Classes - \\[0-9, A-Z, a-z\\] Total number of images - 62\\*40 = 2480\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image details\n",
    "import torch\n",
    "from skimage import io\n",
    "\n",
    "img = io.imread(\"train/Sample001/img001-001.png\")\n",
    "io.imshow(img)\n",
    "print(torch.tensor(img).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Establishing baselines****\n",
    "\n",
    "In solving this task, my first approach was to establish a baseline\n",
    "using a barebones CNN with minimal features. The outcome of this subtask\n",
    "would be to assess performance on the dataset and provide a baseline for\n",
    "future measurements. Pytorch and the Pytorch-lightning framework are\n",
    "used in developing the neural network for this task. Pytorch Lightning\n",
    "provides a high level API in developing the networks, while organizing\n",
    "the code and making it easier to modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from skimage import io\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Data Loading****\n",
    "\n",
    "For handling all tasks relating to data and its loading, Pytorch\n",
    "Lightning provides `LightningDataModule` [1], which wraps Pytorch's\n",
    "`Dataset` and `DataLoader` abstractions, and provides a single interface\n",
    "to access data.\n",
    "\n",
    "The image paths and the classes to which they belong to are loaded from\n",
    "the provided base directory. Initially, the images themselves were\n",
    "loaded into memory instead of their filepaths, but my system was unable\n",
    "to load the entrie dataset due to lack of memory. Thus the paths are\n",
    "loaded, and during training, the images will be loaded using these\n",
    "paths.\n",
    "\n",
    "Cross-entropy is widely used as a loss function when optimizing\n",
    "classification models [2], allowing us to quantify the difference\n",
    "between the target probability distribution and the distribution of the\n",
    "model's output.\n",
    "\n",
    "In PyTorch, CrossEntropyLoss [3] expects *a list of class indices \\[0,\n",
    "C-1\\]*, which means the target vector of classnames must be encoded into\n",
    "a vector of integers. sklearn's `LabelEncoder()` transforms the target\n",
    "vector into the appropriate encoding.\n",
    "\n",
    "Finally, `train_test_split` is used to split the dataset into training,\n",
    "validation and testing sets according to an 80-10-10 split.\n",
    "\n",
    "[1] [LightningDataModule](https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html)\n",
    "\n",
    "[2] [A Gentle Introduction to Cross-Entropy for Machine\n",
    "Learning](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)\n",
    "\n",
    "[3] [PyTorch\n",
    "CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumbersAndLettersDataset(Dataset):\n",
    "    ''' Dataset for numbers and letters. '''\n",
    "    def __init__(self, input_data, target, transform=None):\n",
    "        self.input_data = input_data\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = torch.tensor(io.imread(self.input_data[idx]))\n",
    "        img = img.permute(2, 0, 1) # Reshape to bring channels to first index\n",
    "        return (img, self.target[idx])\n",
    "\n",
    "class NumbersAndLettersModule(pl.LightningDataModule):\n",
    "    ''' DataModule for loading of dataset. '''\n",
    "    def __init__(self, data_dir, batch_size):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.nal_train = None\n",
    "        self.nal_test = None\n",
    "        self.nal_val = None\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage in (None, 'fit'): # Create all datasets\n",
    "            img_dataset, img_classes = self.load_data(self.data_dir)\n",
    "            print(\"Data loaded from disk\")\n",
    "\n",
    "            # Prepare target using Label Encoding\n",
    "            le = LabelEncoder()\n",
    "            le.fit(img_classes)\n",
    "            img_classes = torch.tensor(le.transform(img_classes))\n",
    "\n",
    "            dataset = NumbersAndLettersDataset(img_dataset, img_classes)\n",
    "\n",
    "            # Creating train, test, val datasets according to an 80-10-10 split\n",
    "            self.nal_train, self.nal_test = train_test_split(dataset, test_size=0.1)\n",
    "            self.nal_train, self.nal_val = train_test_split(self.nal_train, test_size=0.1)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.nal_train, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.nal_val, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.nal_test, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def load_data(self, img_dir):\n",
    "        ''' Load image_paths and their classes from disk. '''\n",
    "        dataset = []\n",
    "        classes = []\n",
    "        for folder in os.listdir(img_dir):\n",
    "            img_class = int(folder[-2:]) # Extract last 2 digits of folder name\n",
    "            if img_class < 11:\n",
    "                img_class = str(img_class - 1) # 0-9\n",
    "            elif img_class < 37:\n",
    "                img_class = chr(img_class + 54) # A-Z\n",
    "            else: img_class = chr(img_class + 60) # a-z\n",
    "            for img in os.listdir(os.path.join(img_dir, folder)):\n",
    "                img_path = os.path.join(img_dir, folder, img)\n",
    "                dataset.append(img_path)\n",
    "                classes.append(img_class)\n",
    "        return dataset, classes\n",
    "\n",
    "SEED = 42 # Set a global seed for reproducible results\n",
    "BATCH_SIZE = 4\n",
    "BASE_DIR = \"train\"\n",
    "\n",
    "INPUT_DIM = torch.tensor([3, 900, 1200])\n",
    "\n",
    "pl.utilities.seed.seed_everything(SEED)\n",
    "\n",
    "# Create DataModule to handle loading of dataset\n",
    "data_module = NumbersAndLettersModule(BASE_DIR, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In building the CNN, I decided to implement a simple CNN to understand\n",
    "what the baseline performance looks like. Thus, the design decision in\n",
    "building this CNN were guided by using standard domain knowledge without\n",
    "additional features.\n",
    "\n",
    "**Network Architecture**\n",
    "\n",
    "In designing the network, I referred to CS231, Stanford's course on CNNs\n",
    "[1], in which they present a stacked CONV-RELU followed by POOL layers\n",
    "as the most common architecture. I have opted for a similar design of 4\n",
    "repeating CONV-POOL-RELU stacks. After this, the output of the 4th stack\n",
    "is flattened into a 1D vector and then fed to three fully connected\n",
    "layers, gradually bringing down the dimensionality of the vector to that\n",
    "of the number of output classes.\n",
    "\n",
    "In PytorchLightning, the `LightningModule` is used to build neural nets,\n",
    "and it exposes various methods to simplify the process.\n",
    "\n",
    "1.  `forward` -\\> The forward pass.\n",
    "2.  `configure_optimizers` -\\> Return the optimizer to be used in\n",
    "    training\n",
    "3.  `{training, validation, test}_step` -\\> These functions expose the\n",
    "    training, validation and test loops respectively. In these\n",
    "    functions, the input is propagated through the network, following\n",
    "    which the cross entropy loss is computed.\n",
    "\n",
    "*Loss* -\\> As common in classification tasks, Cross Entropy Loss is\n",
    "used. *Optimizer* -\\> Again, the standard choice is the Adam optimizer\n",
    "and it has been selected.\n",
    "\n",
    "**Logging**\n",
    "\n",
    "I consider logging very important, especially while experimenting with\n",
    "different architectures, it is important to have a baseline stored so\n",
    "future changes can be compared against it. For logging, I have used the\n",
    "Weights and Biases logger integrated into Pytorch Lightning. It allows\n",
    "for live tracking on their website and export of results.\n",
    "\n",
    "[1] [CS231N](https://cs231n.github.io/convolutional-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NumbersAndLettersCNN(pl.LightningModule):\n",
    "    ''' Implementation of CNN to detect numbers and letters. '''\n",
    "    def __init__(self, input_dim, output_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_dim[0], 16, 6)\n",
    "        self.conv2 = nn.Conv2d(16, 64, 6)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 6)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 6)\n",
    "        self.pool = nn.MaxPool2d(3)\n",
    "        self.fc1 = nn.Linear(256 * 8 * 12, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 256)\n",
    "        self.fc3 = nn.Linear(256, output_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Forward pass '''\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x.float())\n",
    "        loss = F.cross_entropy(output, y.long())\n",
    "        self.log('train_loss', loss, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x.float())\n",
    "        loss = F.cross_entropy(output, y.long())\n",
    "        acc = torch.mean((torch.argmax(output, axis=1) == y).float())\n",
    "        self.log_dict({'val_loss': loss, 'val_acc': acc})\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x.float())\n",
    "        loss = F.cross_entropy(output, y.long())\n",
    "        acc = torch.mean((torch.argmax(output, axis=1) == y).float())\n",
    "        self.log_dict({'test_loss': loss, 'test_acc': acc})\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "MODEL_NAME = 'numbers-and-letters-cnn'\n",
    "\n",
    "INPUT_DIM = torch.tensor([3, 900, 1200])\n",
    "OUTPUT_CLASSES = 62\n",
    "\n",
    "# Train and test model\n",
    "\n",
    "model = NumbersAndLettersCNN(INPUT_DIM, OUTPUT_CLASSES)\n",
    "\n",
    "# Log metrics to WandB\n",
    "wandb_logger = pl.loggers.WandbLogger(save_dir='logs/',\n",
    "                                        name=\"%s.pth\" %MODEL_NAME,\n",
    "                                        project='midas-task-2')\n",
    "trainer = pl.Trainer(gpus=1, logger=wandb_logger, max_epochs=1)\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(model=model, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I started training the model, I quickly ran into Out-of-Memory\n",
    "exceptions. I am training on a laptop with 4GB VRAM, and the network I\n",
    "had initially designed was too large for my machine. My first approach\n",
    "was to reduce the batch size from 64 progressively until 4.\n",
    "\n",
    "Even this was not sufficient for the network to run on my GPU and my\n",
    "next approach was to more aggressively use the Convolution and Pooling\n",
    "layers. The Pooling Layer's kernel size was increased to (3,3) from\n",
    "(2,2) to reduce the input vector size faster and similarly the size of\n",
    "the kernel of the Conv2D layers was also increased from (5,5) to (6,6),\n",
    "convolving over a larger window each time.\n",
    "\n",
    "With these enhancements, I was able to run the network on my machine,\n",
    "complete a training loop on one epoch, fix the bugs and complete the\n",
    "training pipeline.\n",
    "\n",
    "Since the model was very large (\\~400MB) and required a lot of time to\n",
    "train even one epoch, I decided to modify the architecture referring to\n",
    "CS231N [1] and a StackOverflow question [2] asking about the handling of\n",
    "large images in CNNs. Since the input images were \\[3, 1200, 900\\], a\n",
    "large image, especially for simple classification of letters/numbers,\n",
    "the following changes were implemented:\n",
    "\n",
    "1.  Reduce the number of FC layers to have a more manageable network -\\>\n",
    "    Since FC layers take most of the parameters (and hence contribute\n",
    "    the most to model size) because they are densely connected, only one\n",
    "    FC layer is now used.\n",
    "2.  Downsample the image before passing it into the network -\\> The\n",
    "    image is MaxPooled once *before* being passed into the network, so\n",
    "    that the network doesn't need to handle sucha a large image.\n",
    "3.  Since the classification is fairly simple, increase the stride of\n",
    "    the Conv layers -\\> For further \"downsampling\", increase the stride\n",
    "    to (2,2) from (1,1) so as to reduce the vector to a manageable size.\n",
    "4.  Apply pooling on alternate convolutions -\\> Since pooling is a\n",
    "    destructive operation, it is applied after every two convolutions\n",
    "    rather than after each. This also compensates for the previous two\n",
    "    points which reduce the size of the input tensor.\n",
    "\n",
    "An EarlyStopping callback was also added, monitoring the validation loss\n",
    "and stopping training if the metric ceased to decrease for 3 consecutive\n",
    "epochs.\n",
    "\n",
    "With the above changes, NumbersAndLettersCNN v2 was tested.\n",
    "\n",
    "[1] [CS231N](https://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "[2] [How do I handle large images when training a\n",
    "CNN?](https://ai.stackexchange.com/questions/3938/how-do-i-handle-large-images-when-training-a-cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NumbersAndLettersCNN V2\n",
    "\n",
    "class NumbersAndLettersCNN(pl.LightningModule):\n",
    "    ''' Implementation of CNN to detect numbers and letters. '''\n",
    "    def __init__(self, input_dim, output_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_dim[0], 64, 3, padding=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 256, 3, padding=2, stride=2)\n",
    "        self.pool = nn.MaxPool2d(4)\n",
    "        self.fc1 = nn.Linear(256 * 14 * 19, output_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Forward pass '''\n",
    "        x = self.pool(x) # Downsample image\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x.float())\n",
    "        loss = F.cross_entropy(output, y.long())\n",
    "        self.log('train_loss', loss, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x.float())\n",
    "        loss = F.cross_entropy(output, y.long())\n",
    "        acc = torch.mean((torch.argmax(output, axis=1) == y).float())\n",
    "        self.log_dict({'val_loss': loss, 'val_acc': acc}, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x.float())\n",
    "        loss = F.cross_entropy(output, y.long())\n",
    "        acc = torch.mean((torch.argmax(output, axis=1) == y).float())\n",
    "        self.log_dict({'test_loss': loss, 'test_acc': acc}, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, logger=wandb_logger,\n",
    "                     callbacks=[early_stopping], min_epochs=5)\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(model=model, datamodule=data_module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result was quite unexpected. While the training loss kept going\n",
    "down, the validation loss started increasing after the very first epoch\n",
    "itself, indicating *overfitting*. After checking for other errors in the\n",
    "implementation, I concluded that it was indeed overfitting and that a\n",
    "much smaller and simpler model would be sufficient. The information that\n",
    "MNIST (28x28) and CIFAR-10 (32x32) could be classified to high\n",
    "accuracies using such small input images led me to work on input\n",
    "preprocessing as the next step.\n",
    "\n",
    "As part of input preprocessing, I took the following steps:\n",
    "\n",
    "1.  Resize input image - Since popular datasets like CIFAR and MNIST can\n",
    "    be learnt very well using only \\~30x30 images, I downsampled the\n",
    "    images drastically from 900x1200 to 30x40 \\[a 30x decrease\\].\n",
    "2.  Grayscale images - To reduce the amount of data even further, I\n",
    "    transformed the images into grayscale. Since the dataset only\n",
    "    consists of black text on a white background, I considered it\n",
    "    sufficient to have one channel rather than 3.\n",
    "3.  Augmentation - Finally, I added a *Gaussian Blur* transformation, to\n",
    "    augment the data and reduce the possibility of overfitting.\n",
    "\n",
    "With these modifications, I trained the model again, and it started\n",
    "overfitting after the first few epochs itself, not managing to climb\n",
    "above 40% in validation accuracy. My next experiments were with\n",
    "different architectures, including popular ones like LeNet [1], to no\n",
    "avail, the model still overfit after a few epochs.\n",
    "\n",
    "Finally, considering that there might be something wrong with the\n",
    "implementation itself, I tested the model against traditional MNIST\n",
    "data, against which it performed very well, reaching around 98%\n",
    "accuracy. This verified the correctness of my implementation and\n",
    "confirmed that the problem was with the data processing.\n",
    "\n",
    "From training with MNIST, I realized three things:\n",
    "\n",
    "1.  Colour inversion - MNIST data is white text (pixel colour 255) on\n",
    "    black background (pixel colour 0). This meant that the majority of\n",
    "    pixels were 0 and the pixels of interest had high values, whereas it\n",
    "    was the opposite in the LettersAndNumbers dataset. Intuitively and\n",
    "    according to [2], the weights corresponding to a 0 in the input will\n",
    "    not be updated, causing poor learning. Thus, as part of the input\n",
    "    pipeline, I included an **inversion** step to invert the colour of\n",
    "    the input image.\n",
    "2.  Normalization - Up to this point, I had not considered the input\n",
    "    values going into the network and seeing MNIST tutorials normalizing\n",
    "    input data, I realized that I was not performing normalization. I\n",
    "    computed the mean and stddev of the dataset and then normalized the\n",
    "    data with this information.\n",
    "3.  Dataset size - MNIST only has 10 classes to classify into, and yet a\n",
    "    dataset of 60000 images is used. In this case, nearly 30x less\n",
    "    images are used to classify 6x more classes. This made me realize\n",
    "    why the model was overfitting so quickly and I added more\n",
    "    transformations to the pipeline. Namely RandomRotation to rotate the\n",
    "    image randomly by (-30, 30) degrees and a Noise function, to add\n",
    "    some Gaussian noise to the image. Finally, I added dropout with\n",
    "    probability 0.8 on the input layer and 0.5 on the hidden layers, to\n",
    "    force the network to be more robust. [3]\n",
    "\n",
    "[1] [Review: LeNet-1, LeNet-4, LeNet-5, Boosted LeNet-4 (Image\n",
    "Classification)](https://sh-tsang.medium.com/paper-brief-review-of-lenet-1-lenet-4-lenet-5-boosted-lenet-4-image-classification-1f5f809dbf17)\n",
    "\n",
    "[2] [Impact of inverting grayscale values on mnist\n",
    "dataset](https://stats.stackexchange.com/questions/220164/impact-of-inverting-grayscale-values-on-mnist-dataset?noredirect=1&lq=1)\n",
    "\n",
    "[3] [A Gentle Introduction to Dropout for Regularizing Deep Neural\n",
    "Networks](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The get item function from the NumbersAndLettersDataset\n",
    "# Image is read as grayscale, inverted and transformed before being passed through the network\n",
    "def __getitem__(self, idx):\n",
    "    img = io.imread(self.input_data[idx], as_gray=True)\n",
    "    img = torch.tensor(util.invert(img)) # Invert colours to be white on black\n",
    "    img = torch.unsqueeze(img, 0)\n",
    "    if self.transform: img = self.transform(img)\n",
    "    return (img, self.target[idx])\n",
    "\n",
    "# Transformation pipeline\n",
    "# Images are resized, normalized and then augmented with [Blur, Rotation, Noise] as part of the pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((30, 40)), # Scale down image\n",
    "    transforms.Normalize((0.0583), (0.2322)),\n",
    "    transforms.GaussianBlur(3),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.Lambda(lambda img: img + np.random.normal(size=np.array(img.shape), scale=0.05)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these changes I trained the network again. While the model\n",
    "overfitted again, the performance was better this time, with validation\n",
    "accuracy going above 50%"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
